{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ignorar sklearn warnings\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning, module='skimage')\n",
    "\n",
    "# Librería de ámbito matemático, científico y de ingeniería. En nuestro caso, solo usamos la convolución.\n",
    "from scipy.ndimage import convolve\n",
    "\n",
    "# Librería para la computación científica. En nuestro caso, la usamos por la representación de datos y hacer calculas de forma\n",
    "# rápida.\n",
    "import numpy as np\n",
    "\n",
    "# Librerías de visión por computador\n",
    "# OpenCV: Generalista.\n",
    "# Skimage: Generalista.\n",
    "# Dlib: Menos funcionalidades, muy rápido e implementaciones muy interesantes.\n",
    "import dlib\n",
    "import cv2\n",
    "from skimage import io\n",
    "from skimage import color\n",
    "from skimage import filters\n",
    "from skimage import util\n",
    "\n",
    "# Librerías para gráficos en 2d/3d. En nuestro caso para mostrar las imágenes y gráficos en general.\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "# Necesario para visualizar los resultados en la misma página.\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fundamentos\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!dir resources"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cargar una imagen en BN o RGB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Si la imagen es grayscale se puede cargar directamente.\n",
    "img_grayscale = io.imread(\"resources/session1/altran_grayscale.png\")\n",
    "\n",
    "# Si la imagen es en color pero la queremos cargar en grayscale hay dos opciones\n",
    "# 1. Usar imread con el parámetro as_grey=True (el tipo será float64).\n",
    "print(\"Tiempo gastado en la opción 1:\")\n",
    "%time img_grayscale = io.imread(\"resources/session1/altran.jpg\", as_grey=True)\n",
    "# Convertir a uint8.\n",
    "%time img_grayscale = img_grayscale.astype(np.uint8)\n",
    "\n",
    "# 2. Cargar la imagen en color y convertirla.\n",
    "print(\"Tiempo gastado en la opción 2:\")\n",
    "%time img = io.imread(\"resources/session1/altran.jpg\")\n",
    "%time img_grayscale = color.rgb2gray(img)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mostrar imagen/es\n",
    "La forma más sencilla para mostrar las imágenes es usar matplotlib con la instrucción imshow(), el uso más básico se muestra a continuación pero podéis encontrar muchos mas ejemplos de uso en https://matplotlib.org/users/image_tutorial.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "f, (ax0, ax1) = plt.subplots(1, 2, figsize=(20, 10))\n",
    "# Grayscale\n",
    "ax0.imshow(img_grayscale, cmap='gray');\n",
    "# Color\n",
    "ax1.imshow(img);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dimensiones de una imagen\n",
    "\n",
    "Tipo de imagen | Coordenadas\n",
    "-- | --\n",
    "2D grayscale | \t(filas, columnas)\n",
    "2D multicanal | (filas, columnas, canal)\n",
    "3D grayscale | \t(plano, filas, columnas)\n",
    "3D multicanal | (plano, filas, columnas, canal)\n",
    "\n",
    "## Las imágenes son numpy arrays!!!\n",
    "Las imágenes se representan en scikit-image usando los standards definidos en numpy. Esto maximiza la inter-operabilidad con otras librerías en el ecosistema del Python científico, como por ejemplo son el caso de matplotlib, sklearn, opencv, dlib o scipy.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(\"Dimensiones (Grayscale):\", img_grayscale.shape)\n",
    "print(\"Dimensiones (Color):\", img.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tipos de datos y valores en la imagen\n",
    "\n",
    "Tipo de datos | Valores\n",
    "-- | --\n",
    "bool  |     de 0 a 1\n",
    "uint8  |     de 0 a 255\n",
    "uint16  |    de 0 a 65535\n",
    "uint32  |   de 0 a 4294967295\n",
    "uint64  |   de 0 a 18446744073709551615\n",
    "int8    |   de -128 a 127\n",
    "int16   |   de -32768 a 32767\n",
    "int32   |   de -2147483648 a 2147483647\n",
    "int64   |   de -9223372036854775808 a 9223372036854775807\n",
    "float32  |   números reales (coma flotante) de 32 bits (según IEEE-754)\n",
    "float64  |  números reales (coma flotante) de 64 bits (según IEEE-754)\n",
    "\n",
    "Scikit-image permite todas las convenciones determinando el tipo de datos del array. Por ejemplo determinando np.uint8 estamos usando el rango de 0-255. Mirar este ejemplo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# + info: https://matplotlib.org/tutorials/colors/colormaps.html\n",
    "print(\"Linspace\\n\"+ \"*\"*32)\n",
    "print(np.linspace(0, 1, 2500))\n",
    "print(np.linspace(0, 255, 2500)[:-10])\n",
    "print(np.linspace(0, 255, 2500)[:-10].astype(np.uint8)[:-10])\n",
    "print(\"\\nEjemplo\\n\" + \"*\"*32)\n",
    "linear0 = np.linspace(0, 1, 2500).reshape((50, 50))\n",
    "linear1 = np.linspace(0, 255, 2500).reshape((50, 50)).astype(np.uint8)\n",
    "\n",
    "print(\"Linear0:\", linear0.dtype, linear0.min(), linear0.max())\n",
    "print(\"Linear1:\", linear1.dtype, linear1.min(), linear1.max())\n",
    "\n",
    "fig, (ax0, ax1) = plt.subplots(1, 2)\n",
    "ax0.imshow(linear0, cmap='gray')\n",
    "ax1.imshow(linear1, cmap='gray');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generar imágenes\n",
    "Como las imágenes se representan con numpy, podemos definir fácilmente una imagen, a continuación dos ejemplos:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Imagen a partir de valores aleatorios.\n",
    "random_image = np.random.random([500, 500])\n",
    "\n",
    "# Imagen en rojo.\n",
    "red_image = np.zeros((500, 500, 3))\n",
    "red_image[:,:,0] = 1\n",
    "\n",
    "# Mostrar las imágenes.\n",
    "f, (ax0, ax1) = plt.subplots(1, 2, figsize=(20, 10))\n",
    "ax0.imshow(random_image, cmap='gray');\n",
    "ax1.imshow(red_image);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modificar imágenes\n",
    "De la misma manera que generar imágenes es fácil, lo mismo sucede con la modificación. A continuación varios ejemplos con diferentes casos de uso."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Ej 1: Dibujar un cuadrado de forma \"manual\".\n",
    "\n",
    "# Grayscale.\n",
    "img_grayscale_copy = img_grayscale.copy()\n",
    "img_grayscale_copy[100:150,100:150] = 0\n",
    "\n",
    "# Color.\n",
    "img_copy = img.copy()\n",
    "img_copy[100:150,100:150, :] = (255, 0, 0)\n",
    "\n",
    "# Mostrar las imágenes.\n",
    "f, (ax0, ax1) = plt.subplots(1, 2, figsize=(20, 10))\n",
    "ax0.imshow(img_grayscale_copy, cmap='gray');\n",
    "ax1.imshow(img_copy);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ej. 2: Método para dibujar una letra H en las coordenadas especificadas de forma \"manual\"\n",
    "def dibujar_H(image, coords, color=(255, 0, 0), in_place=False):\n",
    "    \"\"\"\n",
    "    Este metódo dibuja una H en las coordenadas específicadas con el color específicado.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    image: np.array()\n",
    "        Imagen de entrada.\n",
    "    coords: tuple of int\n",
    "        (Coordenada X, Coordenada Y)\n",
    "    color: tuple of int\n",
    "        RGB color (R, G , B)\n",
    "    in_place: boolean\n",
    "        Devolver una copia de la imagen o la misma imagen\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    np.array()\n",
    "        Imagen con la H dibujada.\n",
    "    \"\"\"\n",
    "    if in_place:\n",
    "        out = image\n",
    "    else:\n",
    "        out = image.copy()\n",
    "    \n",
    "    canvas = out[coords[0]:coords[0] + 24,\n",
    "                 coords[1]:coords[1] + 20]\n",
    "    \n",
    "    canvas[:, :3] = color\n",
    "    canvas[:, -3:] = color\n",
    "    canvas[11:15] = color\n",
    "    \n",
    "    return out\n",
    "\n",
    "img_copy = img.copy()\n",
    "img_copy_H = dibujar_H(img_copy, (50, -50))\n",
    "plt.imshow(img_copy_H);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**ALERTA para navegantes: Estos ejemplos SOLO són útiles para entender como se representa una imagen, para escribir texto o dibujar en una imagen existen métodos específicos para ello en las diferentes librerías de visión por computador**\n",
    "\n",
    "Ahora introduciremos la líbreria OpenCV que incluye algorítmos de Visión por computador, pero además metodos para dibujar facilmente en nuestras imagenes y de esta forma marcar nuestros puntos de interés!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# OpenCV:  Texto, círculo y texto. Identificar cual corresponde a cada instrucción.\n",
    "img_copy = img.copy()\n",
    "cv2.rectangle(img_copy, (20, 20), (55, 55), (0, 255, 0), 2)\n",
    "cv2.rectangle(img_copy, (400,100), (55, 55), (255, 0, 0), 2)\n",
    "cv2.circle(img_copy, (700, 150), 40, (255, 0, 0), 4)\n",
    "cv2.circle(img_copy, (700, 150), 20, (255, 0, 0), -1)\n",
    "cv2.putText(img_copy, \"Objeto #\" + str(1), (190,195),cv2.FONT_HERSHEY_SIMPLEX, 0.8, (0, 0, 255), 2)\n",
    "plt.imshow(img_copy);\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ejercicios propuestos\n",
    "\n",
    "__Ejercicio 1: Implementar un método que dada una posición de píxel te devuelva su valor.__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_pixel_value(image, coords):\n",
    "    \"\"\"\n",
    "    Devuelve el valor RGB de un píxel en una imagen.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    image: np.array()\n",
    "        Imagen de entrada.\n",
    "    coords: tuple of int\n",
    "        (Coordenada X, Coordenada Y).\n",
    "    \n",
    "    Return\n",
    "    ------\n",
    "    tuple of int\n",
    "        Valor del píxel.\n",
    "    \"\"\"\n",
    "    # Aquí tu código\n",
    "    color_tuple = ()\n",
    "    \n",
    "    return color_tuple\n",
    "\n",
    "# Estas líneas verifican tu implementación si devuelven True el resultado es correcto.\n",
    "print(get_pixel_value(img, (150,150)) == (252, 253, 247))\n",
    "print(get_pixel_value(img_grayscale, (150,150)) == 0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___Ejercicio 2: Añadir el código necesario para tener una función similar a la anterior pero con el objetivo de dibujar una L___"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dibujar_L(image, coords, color=(255, 0, 0), in_place=False):\n",
    "    \"\"\"\n",
    "    Este metódo dibuja una letra L en las coordenadas específicadas con el color específicado.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    image: np.array()\n",
    "        Imagen de entrada.\n",
    "    coords: tuple of int\n",
    "        (Coordenada X, Coordenada Y)\n",
    "    color: tuple of int\n",
    "        RGB color (R, G , B)\n",
    "    in_place: boolean\n",
    "        Devolver una copia de la imagen o la misma imagen\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    np.array()\n",
    "        Imagen con la letra L dibujada.\n",
    "    \"\"\"\n",
    "    if in_place:\n",
    "        out = image\n",
    "    else:\n",
    "        out = image.copy()\n",
    "    \n",
    "    # Aquí tu código\n",
    "    \n",
    "    return out\n",
    "\n",
    "# Estas líneas muestran la imágen para verificar visualmente el resultado.\n",
    "img_copy = img.copy()\n",
    "img_copy_H = dibujar_L(img_copy, (50, -50))\n",
    "plt.imshow(img_copy_H);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___Ejercicio 3: Añadir el código necesario para dibujar un cuadrado en la boca y dos círculos en los ojos del personaje que aparece a continuación___"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Carga una nueva imagen\n",
    "img_copy = io.imread(\"resources/session1/billy.jpg\")\n",
    "# Aquí vuestro código\n",
    "\n",
    "# Estas líneas muestran la imágen para verificar visualmente el resultado.\n",
    "plt.imshow(img_copy);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Filtrado de imagen\n",
    "\n",
    "## Filtros locales en imagen\n",
    "Para este primer ejemplo vamos a usar un caso bien simple para reforzar la comprensión de lo que hemos explicado previamente.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generamos una imagen para luego aplicarle nuestro filtro.\n",
    "cuadrado_blanco = np.zeros((7, 7), dtype=float)\n",
    "cuadrado_blanco[2:5, 2:5] = 1\n",
    "\n",
    "# Mostramos la imagen generada.\n",
    "plt.imshow(cuadrado_blanco, cmap=\"gray\");\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Filtro promedio\n",
    "Usaremos como primer ejemplo de filtro, lo que se conoce como el filtro \"promedio\". Para cada píxel un kernel define que píxel vecinos se deben considerar y que peso tienen en nuestro resultado final, de esta forma aplicar un filtro lineal consistirá en:\n",
    "\n",
    "* Centrar el kernel en un píxel actual.\n",
    "* Multiplicar los pixeles afectados con el kernel.\n",
    "* Sumar todos los resultados.\n",
    "* Reemplazar el valor del píxel central con el resultado de la suma."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "filtro_promedio = 1.0/9.0 * np.ones((3, 3))\n",
    "\n",
    "# Muestra los valores\n",
    "print(filtro_promedio)\n",
    "print(cuadrado_blanco)\n",
    "print(convolve(filtro_promedio, cuadrado_blanco))\n",
    "\n",
    "# Muestra gráficamente. PD: Este es un ejemplo también de como mostrar varios gráficos en una misma celda.\n",
    "f, (ax0, ax1, ax2) = plt.subplots(1, 3, figsize=(10, 10))\n",
    "ax0.imshow(filtro_promedio);\n",
    "ax1.imshow(cuadrado_blanco,  cmap='gray');\n",
    "ax2.imshow(convolve(cuadrado_blanco, filtro_promedio),  cmap='gray');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Demo interactiva\n",
    "\n",
    "** Alerta: ** No pretendo que entendáis el código (todo y que no es muy complicado!) el objetivo principal es reforzar la comprensión de como funcionan los filtros."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#------------------------------------------------------------------------------------------------------------------------\n",
    "#  From: https://tonysyu.github.io/ipython-jupyter-widgets-an-image-convolution-demo.html#.WstHHohubIU\n",
    "#------------------------------------------------------------------------------------------------------------------------\n",
    "from skimage import color\n",
    "from scipy import ndimage as ndi\n",
    "from matplotlib import patches\n",
    "\n",
    "def mean_filter_demo(image, vmax=1):\n",
    "    mean_factor = 1.0 / 9.0  # This assumes a 3x3 kernel.\n",
    "    iter_kernel_and_subimage = iter_kernel(image)\n",
    "\n",
    "    image_cache = []\n",
    "\n",
    "    def mean_filter_step(i_step):\n",
    "        while i_step >= len(image_cache):\n",
    "            filtered = image if i_step == 0 else image_cache[-1][-1][-1]\n",
    "            filtered = filtered.copy()\n",
    "\n",
    "            (i, j), mask, subimage = next(iter_kernel_and_subimage)\n",
    "            filter_overlay = color.label2rgb(mask, image, bg_label=0,\n",
    "                                             colors=('cyan', 'red'))\n",
    "            filtered[i, j] = np.sum(mean_factor * subimage)\n",
    "            image_cache.append(((i, j), (filter_overlay, filtered)))\n",
    "\n",
    "        (i, j), images = image_cache[i_step]\n",
    "        fig, axes = plt.subplots(1, len(images), figsize=(10, 5))\n",
    "        \n",
    "        for ax, imc in zip(axes, images):\n",
    "            ax.imshow(imc, vmax=vmax)\n",
    "            rect = patches.Rectangle([j - 0.5, i - 0.5], 1, 1, color='yellow', fill=False)\n",
    "            ax.add_patch(rect)\n",
    "            \n",
    "        plt.show()\n",
    "    return mean_filter_step\n",
    "\n",
    "\n",
    "def mean_filter_interactive_demo(image):\n",
    "    from ipywidgets import IntSlider, interact\n",
    "    mean_filter_step = mean_filter_demo(image)\n",
    "    step_slider = IntSlider(min=0, max=image.size-1, value=0)\n",
    "    interact(mean_filter_step, i_step=step_slider)\n",
    "\n",
    "\n",
    "def iter_kernel(image, size=1):\n",
    "    \"\"\" Yield position, kernel mask, and image for each pixel in the image.\n",
    "\n",
    "    The kernel mask has a 2 at the center pixel and 1 around it. The actual\n",
    "    width of the kernel is 2*size + 1.\n",
    "    \"\"\"\n",
    "    width = 2*size + 1\n",
    "    for (i, j), pixel in iter_pixels(image):\n",
    "        mask = np.zeros(image.shape, dtype='int16')\n",
    "        mask[i, j] = 1\n",
    "        mask = ndi.grey_dilation(mask, size=width)\n",
    "        #mask[i, j] = 2\n",
    "        subimage = image[bounded_slice((i, j), image.shape[:2], size=size)]\n",
    "        yield (i, j), mask, subimage\n",
    "\n",
    "\n",
    "def iter_pixels(image):\n",
    "    \"\"\" Yield pixel position (row, column) and pixel intensity. \"\"\"\n",
    "    height, width = image.shape[:2]\n",
    "    for i in range(height):\n",
    "        for j in range(width):\n",
    "            yield (i, j), image[i, j]\n",
    "\n",
    "\n",
    "def bounded_slice(center, xy_max, size=1, i_min=0):\n",
    "    slices = []\n",
    "    for i, i_max in zip(center, xy_max):\n",
    "        slices.append(slice(max(i - size, i_min), min(i + size + 1, i_max)))\n",
    "    return slices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_filter_interactive_demo(cuadrado_blanco)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ejercicios propuestos\n",
    "\n",
    "\n",
    "___Ejercicio 1: Tratar de describir/descubrir el efecto que producen los siguientes kernel (podéis buscar en Wikipedia...)___"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from scipy import ndimage as ndi\n",
    "\n",
    "# Cargar la imagen\n",
    "img_copy = io.imread(\"resources/session1/abu.jpg\")\n",
    "img_copy = color.rgb2gray(img_copy)\n",
    "img_copy = util.random_noise(img_copy, mode=\"s&p\")\n",
    "\n",
    "# Definir los filtros\n",
    "filtro1 = np.array([[-1, 0, 1], [-2, 0, 2], [-1, 0, 1]])\n",
    "filtro2 = np.array([[-1, -2, -1], [0, 0, 0], [1, 2, 1]])\n",
    "filtro3 = np.ones((22,22)) / 484.\n",
    "filtro4 = np.array([[0, 0, 0], [0, -1, 0], [0, 0, 0]])\n",
    "\n",
    "img_filtro1 = ndi.convolve(img_copy, filtro1)\n",
    "img_filtro2 = ndi.convolve(img_copy, filtro2)\n",
    "img_filtro3 = ndi.convolve(img_copy, filtro3)\n",
    "img_filtro4 = ndi.convolve(img_copy, filtro4)\n",
    "img_filtro5 = filters.median(img_copy.astype(np.float64))\n",
    "\n",
    "# Aquí tu código\n",
    "f, ((ax0, ax1),(ax2, ax3), (ax4, ax5)) = plt.subplots(3, 2, figsize=(10, 10))\n",
    "ax0.imshow(img_copy, cmap='gray');\n",
    "ax1.imshow(img_filtro1, cmap='gray');\n",
    "ax2.imshow(img_filtro2, cmap='gray');\n",
    "ax3.imshow(img_filtro3, cmap='gray');\n",
    "ax4.imshow(img_filtro4, cmap='gray');\n",
    "ax5.imshow(img_filtro5, cmap='gray');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Descriptores de imagen\n",
    "\n",
    "## Hog Descriptor\n",
    "\n",
    "En esta sección vamos a ir paso a paso por la definición que anteriormente dí sobre el descriptor Histogram of Gradients pero ahora de forma totalmente visual para llenar los vacíos de compresión que hayan quedado.\n",
    "\n",
    "__Nota: Los valores usados en los parámetros de los descriptores no son más que para visualizar fácilmente lo que esta pasando, con esto quiero decir que no uséis siempre estos valores como valores por defecto.__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cálculo de los gradientes\n",
    "\n",
    "Calculamos los gradientes usando los filtros de Sobel:\n",
    "\n",
    "$$ \\mathbf{G_x} = \\begin{bmatrix} \n",
    "-1 & 0 & +1 \\\\\n",
    "-2 & 0 & +2 \\\\\n",
    "-1 & 0 & +1 \n",
    "\\end{bmatrix} $$\n",
    "\n",
    "$$ \\mathbf{G_x} = \\begin{bmatrix} \n",
    "-1 & -2 & -1 \\\\\n",
    "0 & 0 & 0 \\\\\n",
    "+1 & +2 & +1 \n",
    "\\end{bmatrix} $$\n",
    "\n",
    "Y luego la magnitud y la orientación:\n",
    "$$ \\mathbf{|G|} = \\sqrt{ \\mathbf{G_x}^2 + \\mathbf{G_y}^2 } $$\n",
    "\n",
    "$$ \\theta = arctan2(G_{y}, G_{x}) $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definimos los filtros.\n",
    "filtro_gradiente_x = np.array([[-1, 0, 1], [-2, 0, 2], [-1, 0, 1]])\n",
    "filtro_gradiente_y = np.array([[-1, -2, -1], [0, 0, 0], [1, 2, 1]])\n",
    "\n",
    "# Aplicamos los filtros.\n",
    "gx = ndi.convolve(img_grayscale, filtro_gradiente_x)\n",
    "gy = ndi.convolve(img_grayscale, filtro_gradiente_y)\n",
    "\n",
    "# Calculamos la magnitud y la orientación\n",
    "mag = np.sqrt((gy*gy) + (gx * gx))\n",
    "ori = np.degrees(np.arctan2(gx ,gy))\n",
    "\n",
    "# Mostramos los resultados graficamente\n",
    "f, ((ax0, ax1, ax2, ax3)) = plt.subplots(4, 1, figsize=(40, 10))\n",
    "ax0.imshow(gx, cmap='gray');\n",
    "ax0.set_title(\"Gradiente - X dir\");\n",
    "ax1.imshow(gy, cmap='gray');\n",
    "ax1.set_title(\"Gradiente - Y dir\");\n",
    "ax2.imshow(mag, cmap='gray');\n",
    "ax2.set_title(\"Gradiente - Magnitud\");\n",
    "ax3.imshow(ori, cmap='gray');\n",
    "ax3.set_title(\"Gradiente - Orientación\");\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Histograma de los bloques\n",
    "\n",
    "Demo parecida a la de los filtros que nos permite comprender mejor que procedimiento hace el algoritmo en esta fase."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Este método es útil para dividir una imagen en especificando ciertos parámetros\n",
    "from skimage.util.shape import view_as_windows\n",
    "# Este solo lo usamos para crear el ejemplo interactivo\n",
    "from ipywidgets import IntSlider, interact\n",
    "\n",
    "# Generamos todas las ventanas posibles con las dimensiones (50, 50)\n",
    "tamaño_ventana = (50, 50)\n",
    "step = 50 # Si no definimos un step es de 1 y las subventanas se solapan\n",
    "windows = view_as_windows(np.abs(ori.copy()),tamaño_ventana,step=50)\n",
    "img_grayscale_rgb = cv2.cvtColor(img_grayscale.copy().astype(np.uint8),cv2.COLOR_GRAY2RGB)\n",
    "\n",
    "def show_window(iteration):\n",
    "    \"\"\"\n",
    "    Muestra para la iteración n el histograma de los bloques.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    iteration: int\n",
    "        Número de iteración actual.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Define el número de gráficos que mostraremos.\n",
    "    fig = plt.figure(figsize=(15, 15))\n",
    "    ax0 = plt.subplot2grid((2, 2), (0, 0), colspan=2)\n",
    "    ax1 = plt.subplot2grid((2, 2), (1, 0), colspan=1)\n",
    "    ax2 = plt.subplot2grid((2, 2), (1, 1), rowspan=2)\n",
    "\n",
    "    # Tamaño de la subventana\n",
    "    num_rows, num_cols = tamaño_ventana\n",
    "    \n",
    "    # Calcula usando la iteración actual en que posición de la imagen estamos\n",
    "    pos0 = int(iteration % windows.shape[1]) * step\n",
    "    pos1 = int(iteration / windows.shape[1]) * step\n",
    "    \n",
    "    # Dibuja un cuadrado en la imagen y muestralo en la primera gráfica.\n",
    "    img_slide= cv2.cvtColor(mag.copy().astype(np.uint8) * 255,cv2.COLOR_GRAY2RGB)\n",
    "    cv2.rectangle(img_slide, (pos0, pos1), (pos0 + windows.shape[1], pos1 + windows.shape[1]), ((255, 0, 0)), 2)\n",
    "    ax0.imshow(img_slide, cmap='gray');\n",
    "    ax0.set_title(\"Imagen original\")\n",
    "    \n",
    "    # Seleciona la ventana actual en las orientaciones y muestrala en la segunda gráfica\n",
    "    piece = windows[int(iteration / windows.shape[1]),\n",
    "                    int(iteration % windows.shape[1]), :, :]\n",
    "    ax1.imshow(piece, cmap='gray')\n",
    "    ax1.set_title(\"Orientaciones\")\n",
    "    \n",
    "    # Compute and show the histogram\n",
    "    hist, bin_edges = np.histogram(piece, bins = range(0, 180, 20))\n",
    "    ax2.bar(bin_edges[:-1], hist, width=10)\n",
    "    ax2.set_title(\"Histograma de las orientaciones\")\n",
    "    \n",
    "interact(show_window, iteration=(0, windows.shape[0] * windows.shape[1]), default=0);\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normalización de contraste de los bloques\n",
    "\n",
    "![ta](resources/session1/hog_contrast_normalization.gif)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hog descriptor\n",
    "Una vez ya hemos comprendido como se implementa el descriptor, a continuación muestro un ejemplo que solo sirve para ir un paso más adelante, simplemente es una introducción a lo que debe ser un detector pero simplificado a su forma mínima.\n",
    "\n",
    "#### Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "train_path = \"resources/session1/logos/training/\"\n",
    "\n",
    "# Cargamos unos modelos de logos de ejemplo\n",
    "ferchau = io.imread(train_path + \"ferchau.png\", as_grey=True)\n",
    "between = io.imread(train_path + \"between.png\", as_grey=True)\n",
    "capgemini = io.imread(train_path + \"capgemini.png\", as_grey=True)\n",
    "altran = io.imread(train_path + \"altran.jpg\", as_grey=True)\n",
    "\n",
    "# Mostramos las imágenes que hemos cargado\n",
    "f, ((ax0, ax1), (ax2, ax3)) = plt.subplots(2, 2, figsize=(40, 10))\n",
    "ax0.imshow(ferchau, cmap='gray');\n",
    "ax0.set_title(\"Logo ferchau\");\n",
    "ax1.imshow(between, cmap='gray');\n",
    "ax1.set_title(\"Logo between\");\n",
    "ax2.imshow(capgemini, cmap='gray');\n",
    "ax2.set_title(\"Logo capgemini\");\n",
    "ax3.imshow(altran, cmap='gray');\n",
    "ax3.set_title(\"Logo altran\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage.transform import resize\n",
    "from skimage import feature\n",
    "# Redimensionar las imagenes \n",
    "width = 300\n",
    "height = 180\n",
    "\n",
    "altran = resize(altran, (180, 300))\n",
    "ferchau = resize(ferchau, (180, 300))\n",
    "between = resize(between, (180, 300))\n",
    "capgemini = resize(capgemini, (180, 300))\n",
    "\n",
    "# Calculamos los descriptores HOG para cada imagen\n",
    "(altran_descriptor, altran_hogImage) = feature.hog(altran, orientations=9, pixels_per_cell=(8, 8),\n",
    "                                                   cells_per_block=(2, 2), transform_sqrt=True, visualise=True)\n",
    "(ferchau_descriptor, ferchau_hogImage) = feature.hog(ferchau, orientations=9, pixels_per_cell=(8, 8),\n",
    "                                                     cells_per_block=(2, 2), transform_sqrt=True, visualise=True)\n",
    "(between_descriptor, between_hogImage) = feature.hog(between, orientations=9, pixels_per_cell=(8, 8),\n",
    "                                                     cells_per_block=(2, 2), transform_sqrt=True, visualise=True)\n",
    "(capgemini_descriptor, capgemini_hogImage) = feature.hog(capgemini, orientations=9, pixels_per_cell=(8, 8),\n",
    "                                                         cells_per_block=(2, 2), transform_sqrt=True, visualise=True)\n",
    "\n",
    "# Añadir los descriptores a un diccionario\n",
    "descriptores = {}\n",
    "descriptores[\"altran\"] = altran_descriptor\n",
    "descriptores[\"ferchau\"] = ferchau_descriptor\n",
    "descriptores[\"between\"] = between_descriptor\n",
    "descriptores[\"capgemini\"] = capgemini_descriptor\n",
    "\n",
    "# Mostramos las descriptores que hemos calculado\n",
    "f, ((ax0, ax1), (ax2, ax3)) = plt.subplots(2, 2, figsize=(20, 10))\n",
    "ax0.imshow(ferchau_hogImage, cmap='gray');\n",
    "ax0.set_title(\"Logo ferchau\");\n",
    "ax1.imshow(between_hogImage, cmap='gray');\n",
    "ax1.set_title(\"Logo between\");\n",
    "ax2.imshow(capgemini_hogImage, cmap='gray');\n",
    "ax2.set_title(\"Logo capgemini\");\n",
    "ax3.imshow(altran_hogImage, cmap='gray');\n",
    "ax3.set_title(\"Logo altran\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import euclidean_distances\n",
    "\n",
    "test_path = \"resources/session1/logos/test/\"\n",
    "\n",
    "# Cargamos un par de imágenes desconocidas\n",
    "test = io.imread(test_path + \"test.png\", as_grey=True)\n",
    "test2 = io.imread(test_path + \"test2.jpg\", as_grey=True)\n",
    "\n",
    "# Las redimensionamos\n",
    "test = resize(test, (180, 300))\n",
    "test2 = resize(test2, (180, 300))\n",
    "\n",
    "# Calculamos los descriptores HOG para cada imagen\n",
    "(test_descriptor, test_hogImage) = feature.hog(test, orientations=9, pixels_per_cell=(8, 8),\n",
    "                                               cells_per_block=(2, 2), transform_sqrt=True, visualise=True)\n",
    "(test2_descriptor, test2_hogImage) = feature.hog(test2, orientations=9, pixels_per_cell=(8, 8),\n",
    "                                                 cells_per_block=(2, 2), transform_sqrt=True, visualise=True)\n",
    "print(\"Resultados del Test1\")\n",
    "print(\"*\" * 20)\n",
    "# Miramos la distancia euclidia respecto a la primera imagen de test\n",
    "for compañia in descriptores.keys():\n",
    "    print(compañia, \"| L2 distance:\" + str(np.sqrt(np.sum((test_descriptor - descriptores[compañia]) ** 2))))\n",
    "\n",
    "print(\"\\nResultados del Test2\")\n",
    "print(\"*\" * 20)\n",
    "# Miramos la distancia euclidia respecto a la segunda imagen de test\n",
    "for compañia in descriptores.keys():\n",
    "    print(compañia, \"| L2 distance:\" + str(np.sqrt(np.sum((test2_descriptor - descriptores[compañia]) ** 2))))\n",
    "    \n",
    "f, ((ax0, ax1)) = plt.subplots(1, 2, figsize=(20, 10))\n",
    "ax0.imshow(test, cmap='gray');\n",
    "ax0.set_title(\"Test\");\n",
    "ax1.imshow(test2, cmap='gray');\n",
    "ax1.set_title(\"Test2\");"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "273px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
